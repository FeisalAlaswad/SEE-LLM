# -*- coding: utf-8 -*-
"""ML for Story point.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O1QKXEedHZFCZZJ-8I04RARSBvyM0OeZ
"""

!pip install drive

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive/Software Estimation')

import numpy as np
from scipy import sparse
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error


def RandomForestmodel_tf_idf_fast():
    print("Loading dataset...")
    data_csv = pd.read_csv("data_csv/data", low_memory=False)
    y = data_csv["point"]

    print("Loading sparse TF-IDF features...")
    X_sparse = sparse.load_npz("features/tf_idf_matrix.npz")   # KEEP sparse

    # -------------------------------
    # Dimensionality reduction (FAST)
    # -------------------------------
    print("Running Truncated SVD (dim reduction)...")
    svd = TruncatedSVD(n_components=3000, random_state=42)
    X_reduced = svd.fit_transform(X_sparse)   # still very fast

    # --------------------------------
    # Train-test split
    # --------------------------------
    x_train, x_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.3, random_state=42
    )

    # --------------------------------
    # Random Forest (CPU Optimized)
    # --------------------------------
    print("Training Random Forest (CPU optimised)...")
    rf = RandomForestRegressor(
        random_state=99,
        n_estimators=500,
        n_jobs=-1,        # use all CPU cores
        max_features="log2"
    )
    rf.fit(x_train, y_train)

    # Predict
    y_pred = rf.predict(x_test)

    # --------------------------------
    # Metrics
    # --------------------------------
    MAE  = mean_absolute_error(y_test, y_pred)
    MdAE = median_absolute_error(y_test, y_pred)
    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))

    baseline_pred = np.full_like(y_test, y_train.mean())
    MAE_baseline = mean_absolute_error(y_test, baseline_pred)
    SA = 1 - (MAE / MAE_baseline)

    PRED25 = np.mean((np.abs(y_test - y_pred) / y_test) <= 0.25)

    result_total = {
        "MAE": MAE,
        "MdAE": MdAE,
        "RMSE": RMSE,
        "SA": SA,
        "PRED(25)": PRED25
    }

    print("\nâš¡ FAST CPU RandomForest Results:")
    print(result_total)

    return result_total


# Run
result_total = RandomForestmodel_tf_idf_fast()

import os
os.chdir('/content/drive/MyDrive/Software Estimation')

import numpy as np
from scipy import sparse
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error


def SVRmodel_tf_idf_fast():
    print("Loading dataset...")
    data_csv = pd.read_csv("data_csv/data", low_memory=False)
    y = data_csv["point"]

    print("Loading sparse TF-IDF features...")
    X_sparse = sparse.load_npz("features/tf_idf_matrix.npz")   # KEEP sparse

    # -------------------------------
    # Dimensionality reduction (FAST)
    # -------------------------------
    print("Running Truncated SVD (dim reduction)...")
    svd = TruncatedSVD(n_components=3000, random_state=42)
    X_reduced = svd.fit_transform(X_sparse)   # still very fast

    # --------------------------------
    # Train-test split
    # --------------------------------
    x_train, x_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.3, random_state=42
    )

    # --------------------------------
    # SVR
    # --------------------------------
    print("Training SVR (CPU)...")
    svr = SVR(kernel='rbf', C=10, epsilon=0.1)  # You can tune these parameters
    svr.fit(x_train, y_train)

    # Predict
    y_pred = svr.predict(x_test)

    # --------------------------------
    # Metrics
    # --------------------------------
    MAE  = mean_absolute_error(y_test, y_pred)
    MdAE = median_absolute_error(y_test, y_pred)
    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))

    baseline_pred = np.full_like(y_test, y_train.mean())
    MAE_baseline = mean_absolute_error(y_test, baseline_pred)
    SA = 1 - (MAE / MAE_baseline)

    PRED25 = np.mean((np.abs(y_test - y_pred) / y_test) <= 0.25)

    result_total = {
        "MAE": MAE,
        "MdAE": MdAE,
        "RMSE": RMSE,
        "SA": SA,
        "PRED(25)": PRED25
    }

    print("\nâš¡ SVR Results:")
    print(result_total)

    return result_total


# Run
result_total = SVRmodel_tf_idf_fast()

import os
os.chdir('/content/drive/MyDrive/Software Estimation')

import numpy as np
from scipy import sparse
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error

from xgboost import XGBRegressor


def XGBoost_tf_idf_fast():
    print("Loading dataset...")
    data_csv = pd.read_csv("data_csv/data", low_memory=False)
    y = data_csv["point"]

    print("Loading sparse TF-IDF features...")
    X_sparse = sparse.load_npz("features/tf_idf_matrix.npz")   # KEEP sparse

    # -------------------------------
    # Dimensionality reduction (FAST)
    # -------------------------------
    print("Running Truncated SVD (dim reduction)...")
    svd = TruncatedSVD(n_components=3000, random_state=42)
    X_reduced = svd.fit_transform(X_sparse)

    # --------------------------------
    # Train-test split
    # --------------------------------
    x_train, x_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.3, random_state=42
    )

    # --------------------------------
    # XGBoost Regressor
    # --------------------------------
    print("Training XGBoost (CPU optimised)...")
    xgb = XGBRegressor(
        n_estimators=600,
        learning_rate=0.05,
        max_depth=8,
        subsample=0.9,
        colsample_bytree=0.7,
        objective='reg:squarederror',
        eval_metric='mae',
        tree_method='hist',     # FAST CPU algorithm
        random_state=99,
        n_jobs=-1
    )

    xgb.fit(x_train, y_train)

    # Predict
    y_pred = xgb.predict(x_test)

    # --------------------------------
    # Metrics
    # --------------------------------
    MAE  = mean_absolute_error(y_test, y_pred)
    MdAE = median_absolute_error(y_test, y_pred)
    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))

    baseline_pred = np.full_like(y_test, y_train.mean())
    MAE_baseline = mean_absolute_error(y_test, baseline_pred)
    SA = 1 - (MAE / MAE_baseline)

    PRED25 = np.mean((np.abs(y_test - y_pred) / y_test) <= 0.25)

    result_total = {
        "MAE": MAE,
        "MdAE": MdAE,
        "RMSE": RMSE,
        "SA": SA,
        "PRED(25)": PRED25
    }

    print("\nðŸš€ FAST CPU XGBoost Results:")
    print(result_total)

    return result_total


# Run
result_total = XGBoost_tf_idf_fast()

import os
os.chdir('/content/drive/MyDrive/Software Estimation')

import numpy as np
from scipy import sparse
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error


def LinearRegression_tf_idf_fast():
    print("Loading dataset...")
    data_csv = pd.read_csv("data_csv/data", low_memory=False)
    y = data_csv["point"]

    print("Loading sparse TF-IDF features...")
    X_sparse = sparse.load_npz("features/tf_idf_matrix.npz")

    # -------------------------------
    # Dimensionality reduction (SVD)
    # -------------------------------
    print("Running Truncated SVD (dim reduction)...")
    svd = TruncatedSVD(n_components=3000, random_state=42)
    X_reduced = svd.fit_transform(X_sparse)

    # --------------------------------
    # Train-test split
    # --------------------------------
    x_train, x_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.3, random_state=42
    )

    # --------------------------------
    # Linear Regression
    # --------------------------------
    print("Training Linear Regression model...")
    lr = LinearRegression(n_jobs=-1)  # uses CPU parallelization
    lr.fit(x_train, y_train)

    # Predict
    y_pred = lr.predict(x_test)

    # --------------------------------
    # Metrics
    # --------------------------------
    MAE  = mean_absolute_error(y_test, y_pred)
    MdAE = median_absolute_error(y_test, y_pred)
    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))

    # Standardized Accuracy
    baseline_pred = np.full_like(y_test, y_train.mean())
    MAE_baseline = mean_absolute_error(y_test, baseline_pred)
    SA = 1 - (MAE / MAE_baseline)

    # PRED(25)
    PRED25 = np.mean((np.abs(y_test - y_pred) / y_test) <= 0.25)

    result_total = {
        "MAE": MAE,
        "MdAE": MdAE,
        "RMSE": RMSE,
        "SA": SA,
        "PRED(25)": PRED25
    }

    print("\nâš¡ FAST CPU Linear Regression Results:")
    print(result_total)

    return result_total


# Run
result_total = LinearRegression_tf_idf_fast()

import os
os.chdir('/content/drive/MyDrive/Software Estimation')

import numpy as np
from scipy import sparse
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error


def KNNmodel_tf_idf_fast():
    print("Loading dataset...")
    data_csv = pd.read_csv("data_csv/data", low_memory=False)
    y = data_csv["point"]

    print("Loading sparse TF-IDF features...")
    X_sparse = sparse.load_npz("features/tf_idf_matrix.npz")   # KEEP sparse

    # -------------------------------
    # Dimensionality reduction (FAST)
    # -------------------------------
    print("Running Truncated SVD (dim reduction)...")
    svd = TruncatedSVD(n_components=3000, random_state=42)
    X_reduced = svd.fit_transform(X_sparse)

    # --------------------------------
    # Train-test split
    # --------------------------------
    x_train, x_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.3, random_state=42
    )

    # --------------------------------
    # KNN Regression
    # --------------------------------
    print("Training KNN Regression...")
    knn = KNeighborsRegressor(
        n_neighbors=5,          # you can tune this
        weights='distance',     # better for regression
        metric='euclidean',     # default distance metric
        n_jobs=-1               # use all CPU cores
    )
    knn.fit(x_train, y_train)

    # Predict
    y_pred = knn.predict(x_test)

    # --------------------------------
    # Metrics
    # --------------------------------
    MAE  = mean_absolute_error(y_test, y_pred)
    MdAE = median_absolute_error(y_test, y_pred)
    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))

    baseline_pred = np.full_like(y_test, y_train.mean())
    MAE_baseline = mean_absolute_error(y_test, baseline_pred)
    SA = 1 - (MAE / MAE_baseline)

    PRED25 = np.mean((np.abs(y_test - y_pred) / y_test) <= 0.25)

    result_total = {
        "MAE": MAE,
        "MdAE": MdAE,
        "RMSE": RMSE,
        "SA": SA,
        "PRED(25)": PRED25
    }

    print("\nâš¡ FAST CPU KNN Results:")
    print(result_total)

    return result_total


# Run
result_total = KNNmodel_tf_idf_fast()

!pip install statsmodels

import pandas as pd

# ------------------------------------------------
# INSERT YOUR RESULTS HERE
# ------------------------------------------------
results_dict = {
    # ----- ML FAMILY -----
    "SVR": {
        "Family": "ML",
        "MAE": 4.9705, "MdAE": 3.102, "RMSE": 9.884,
        "SA": 0.215, "PRED(25)": 0.312
    },
    "RandomForest": {
        "Family": "ML",
        "MAE": 5.9135, "MdAE": 3.884, "RMSE": 10.442,
        "SA": 0.174, "PRED(25)": 0.287
    },
    "XGBoost": {
        "Family": "ML",
        "MAE": 5.5015, "MdAE": 3.556, "RMSE": 10.115,
        "SA": 0.198, "PRED(25)": 0.295
    },
    "LinearReg": {
        "Family": "ML",
        "MAE": 6.559, "MdAE": 4.102, "RMSE": 11.209,
        "SA": 0.122, "PRED(25)": 0.251
    },
    "KNN": {
        "Family": "ML",
        "MAE": 5.8275, "MdAE": 3.794, "RMSE": 10.671,
        "SA": 0.163, "PRED(25)": 0.279
    },

    # ----- TRANSFORMER FAMILY -----
    "BERT": {
        "Family": "Transformer",
        "MAE": 4.547, "MdAE": 2.951, "RMSE": 9.102,
        "SA": 0.285, "PRED(25)": 0.345
    },
    "RoBERTa": {
        "Family": "Transformer",
        "MAE": 4.209, "MdAE": 2.744, "RMSE": 8.774,
        "SA": 0.312, "PRED(25)": 0.362
    },
    "GPT2": {
        "Family": "Transformer",
        "MAE": 3.885, "MdAE": 2.501, "RMSE": 8.221,
        "SA": 0.348, "PRED(25)": 0.381
    },

    # ----- LLM FAMILY -----
    "GPT-4-Turbo": {
        "Family": "LLM",
        "MAE": 3.742, "MdAE": 2.308, "RMSE": 7.984,
        "SA": 0.362, "PRED(25)": 0.401
    },
    "DeepSeek-V3": {
        "Family": "LLM",
        "MAE": 3.951, "MdAE": 2.445, "RMSE": 8.112,
        "SA": 0.355, "PRED(25)": 0.392
    },
    "Llama-3-70B": {
        "Family": "LLM",
        "MAE": 4.102, "MdAE": 2.591, "RMSE": 8.330,
        "SA": 0.341, "PRED(25)": 0.381
    },
    "Gemini-1.5-Pro": {
        "Family": "LLM",
        "MAE": 3.801, "MdAE": 2.387, "RMSE": 8.052,
        "SA": 0.359, "PRED(25)": 0.396
    }
}

# Convert dict â†’ DataFrame
df = pd.DataFrame.from_dict(results_dict, orient='index').reset_index()

# Rename first column only
df = df.rename(columns={"index": "Model"})
df = df.rename(columns={"PRED(25)": "PRED25"})

print(df)

df["Family"] = df["Family"].astype("category")
df["Family"] = df["Family"].cat.reorder_categories(["ML", "Transformer", "LLM"], ordered=True)

import statsmodels.formula.api as smf

model_lme = smf.mixedlm(
    "MAE ~ Family",
    data=df,
    groups=df["Model"]       # random intercept per model
)

lme_result = model_lme.fit()
print(lme_result.summary())


beta_trans = lme_result.params.get("Family[T.Transformer]")
beta_llm = lme_result.params.get("Family[T.LLM]")
mu = lme_result.params.get("Intercept")

pval_trans = lme_result.pvalues.get("Family[T.Transformer]")
pval_llm = lme_result.pvalues.get("Family[T.LLM]")

print("\n--- Interpretation ---")
print(f"Baseline (ML family) MAE = {mu:.3f}")

print(f"Transformer effect (Î²_Trans) = {beta_trans:.3f}  | p = {pval_trans:.5f}")
print(f"LLM effect (Î²_LLM) = {beta_llm:.3f}          | p = {pval_llm:.5f}")

# Significance interpretation
if pval_trans < 0.001:
    print("âœ” Transformer family differs significantly from ML (p < 0.001)")

if pval_llm < 0.001:
    print("âœ” LLM family differs significantly from ML (p < 0.001)")